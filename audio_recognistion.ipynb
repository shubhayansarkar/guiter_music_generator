{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5869654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c00df734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "df=pd.read_csv(r'C:\\mine\\guitar_notes_classification\\audiofiles\\preprocessed_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c96842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-4.1302170e+02  1.4175392e+02  2.6291016e+01 ...</td>\n",
       "      <td>Dha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-4.1302170e+02  1.4175392e+02  2.6291016e+01 ...</td>\n",
       "      <td>Dha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-4.1302170e+02  1.4175392e+02  2.6291016e+01 ...</td>\n",
       "      <td>Dha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-4.1302170e+02  1.4175392e+02  2.6291016e+01 ...</td>\n",
       "      <td>Dha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-4.1302170e+02  1.4175392e+02  2.6291016e+01 ...</td>\n",
       "      <td>Dha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38759</th>\n",
       "      <td>[-344.25223     163.62611      13.576447     1...</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38760</th>\n",
       "      <td>[-344.25223     163.62611      13.576447     1...</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38761</th>\n",
       "      <td>[-344.25223     163.62611      13.576447     1...</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38762</th>\n",
       "      <td>[-344.25223     163.62611      13.576447     1...</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38763</th>\n",
       "      <td>[-344.25223     163.62611      13.576447     1...</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38764 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 feature class\n",
       "0      [-4.1302170e+02  1.4175392e+02  2.6291016e+01 ...   Dha\n",
       "1      [-4.1302170e+02  1.4175392e+02  2.6291016e+01 ...   Dha\n",
       "2      [-4.1302170e+02  1.4175392e+02  2.6291016e+01 ...   Dha\n",
       "3      [-4.1302170e+02  1.4175392e+02  2.6291016e+01 ...   Dha\n",
       "4      [-4.1302170e+02  1.4175392e+02  2.6291016e+01 ...   Dha\n",
       "...                                                  ...   ...\n",
       "38759  [-344.25223     163.62611      13.576447     1...    sa\n",
       "38760  [-344.25223     163.62611      13.576447     1...    sa\n",
       "38761  [-344.25223     163.62611      13.576447     1...    sa\n",
       "38762  [-344.25223     163.62611      13.576447     1...    sa\n",
       "38763  [-344.25223     163.62611      13.576447     1...    sa\n",
       "\n",
       "[38764 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cae40e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j in range(len(df.feature)):\n",
    "    l1=[]\n",
    "    for i in (df.feature[j].strip('][').split(' ')):\n",
    "        if i !='':\n",
    "            l1.append(float(i.replace('\\n','')))\n",
    "    df.feature[j]=l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1bc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(df['feature'].tolist())\n",
    "y=np.array(df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86341f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "msc=MinMaxScaler()\n",
    "X=msc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6c4fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38764, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "494395ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dha', 'Dha', 'Dha', ..., 'sa', 'sa', 'sa'], dtype='<U3')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c14aa88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder=LabelEncoder()\n",
    "y=labelencoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "781ff103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 6, 6, 6], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72608ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38764,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0146c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38764, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y.reshape(y.shape[0],-1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "162917de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "num_labels=y.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "75125a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d07982f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "382/384 [============================>.] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.1275\n",
      "Epoch 1: val_loss improved from inf to 0.00000, saving model to saved_models\\audio_classification_ann_all.hdf5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_models/audio_classification_ann_all.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\engine\\training.py:1624\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m     }\n\u001b[0;32m   1622\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> 1624\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1625\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\callbacks.py:448\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    446\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 448\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\callbacks.py:1463\u001b[0m, in \u001b[0;36mModelCheckpoint.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs_since_last_save \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1463\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\callbacks.py:1528\u001b[0m, in \u001b[0;36mModelCheckpoint._save_model\u001b[1;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_weights(\n\u001b[0;32m   1523\u001b[0m             filepath,\n\u001b[0;32m   1524\u001b[0m             overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1525\u001b[0m             options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options,\n\u001b[0;32m   1526\u001b[0m         )\n\u001b[0;32m   1527\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1528\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\engine\\training.py:2698\u001b[0m, in \u001b[0;36mModel.save\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   2643\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\n\u001b[0;32m   2645\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2652\u001b[0m     save_traces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2653\u001b[0m ):\n\u001b[0;32m   2655\u001b[0m     \u001b[38;5;124;03m\"\"\"Saves the model to Tensorflow SavedModel or a single HDF5 file.\u001b[39;00m\n\u001b[0;32m   2656\u001b[0m \n\u001b[0;32m   2657\u001b[0m \u001b[38;5;124;03m    Please see `tf.keras.models.save_model` or the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m   2696\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2698\u001b[0m     \u001b[43msave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2699\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2702\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2703\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2704\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2705\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2706\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_traces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2707\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\saving\\save.py:161\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_is_graph_network \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    151\u001b[0m         model, sequential\u001b[38;5;241m.\u001b[39mSequential\n\u001b[0;32m    152\u001b[0m     ):\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving the model to HDF5 format requires the model to be a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunctional model or a Sequential model. It does not work for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msetting save_format=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) or using `save_weights`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    160\u001b[0m         )\n\u001b[1;32m--> 161\u001b[0m     \u001b[43mhdf5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model_to_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_optimizer\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m generic_utils\u001b[38;5;241m.\u001b[39mSharedObjectSavingScope():\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\saving\\hdf5_format.py:141\u001b[0m, in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    131\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    132\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHDF5 format does not save weights of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    133\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `optimizer_experimental.Optimizer`, your optimizer will\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be recompiled at loading time.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m         )\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    137\u001b[0m         include_optimizer\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m model\u001b[38;5;241m.\u001b[39moptimizer\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model\u001b[38;5;241m.\u001b[39moptimizer, optimizer_v1\u001b[38;5;241m.\u001b[39mTFOptimizer)\n\u001b[0;32m    140\u001b[0m     ):\n\u001b[1;32m--> 141\u001b[0m         \u001b[43msave_optimizer_weights_to_hdf5_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     f\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\saving\\hdf5_format.py:695\u001b[0m, in \u001b[0;36msave_optimizer_weights_to_hdf5_group\u001b[1;34m(hdf5_group, optimizer)\u001b[0m\n\u001b[0;32m    693\u001b[0m     param_dset[()] \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 695\u001b[0m     \u001b[43mparam_dset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\h5py\\_hl\\dataset.py:982\u001b[0m, in \u001b[0;36mDataset.__setitem__\u001b[1;34m(self, args, val)\u001b[0m\n\u001b[0;32m    980\u001b[0m mspace \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(selection\u001b[38;5;241m.\u001b[39mexpand_shape(mshape))\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fspace \u001b[38;5;129;01min\u001b[39;00m selection\u001b[38;5;241m.\u001b[39mbroadcast(mshape):\n\u001b[1;32m--> 982\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdxpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dxpl\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "num_batch_size = 16\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification_ann_all.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e15a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14205c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ef8321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xtrainl=X_train.reshape(-1,1,X_train.shape[1])\n",
    "xtestl=X_test.reshape(-1,1,X_test.shape[1])\n",
    "ytrainl=y_train.reshape(-1,1,1)\n",
    "ytestl=y_test.reshape(-1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d39252d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "1939/1939 [==============================] - ETA: 0s - loss: 0.7139\n",
      "Epoch 1: val_loss improved from inf to 0.08786, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 51s 23ms/step - loss: 0.7139 - val_loss: 0.0879\n",
      "Epoch 2/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 0.1099\n",
      "Epoch 2: val_loss improved from 0.08786 to 0.06054, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 41s 21ms/step - loss: 0.1098 - val_loss: 0.0605\n",
      "Epoch 3/100\n",
      "1939/1939 [==============================] - ETA: 0s - loss: 0.0698\n",
      "Epoch 3: val_loss improved from 0.06054 to 0.03203, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 39s 20ms/step - loss: 0.0698 - val_loss: 0.0320\n",
      "Epoch 4/100\n",
      "1939/1939 [==============================] - ETA: 0s - loss: 0.0366\n",
      "Epoch 4: val_loss improved from 0.03203 to 0.01863, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 47s 24ms/step - loss: 0.0366 - val_loss: 0.0186\n",
      "Epoch 5/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 0.0197\n",
      "Epoch 5: val_loss did not improve from 0.01863\n",
      "1939/1939 [==============================] - 43s 22ms/step - loss: 0.0197 - val_loss: 0.0262\n",
      "Epoch 6/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 0.0096\n",
      "Epoch 6: val_loss improved from 0.01863 to 0.01186, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 40s 21ms/step - loss: 0.0096 - val_loss: 0.0119\n",
      "Epoch 7/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.01186 to 0.00418, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 43s 22ms/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 8/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00418 to 0.00171, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 45s 23ms/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 9/100\n",
      "1937/1939 [============================>.] - ETA: 0s - loss: 0.0019\n",
      "Epoch 9: val_loss improved from 0.00171 to 0.00031, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 43s 22ms/step - loss: 0.0019 - val_loss: 3.0554e-04\n",
      "Epoch 10/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 0.0012\n",
      "Epoch 10: val_loss improved from 0.00031 to 0.00030, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 43s 22ms/step - loss: 0.0012 - val_loss: 2.9911e-04\n",
      "Epoch 11/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 8.7956e-04\n",
      "Epoch 11: val_loss did not improve from 0.00030\n",
      "1939/1939 [==============================] - 42s 22ms/step - loss: 8.7956e-04 - val_loss: 9.6124e-04\n",
      "Epoch 12/100\n",
      "1939/1939 [==============================] - ETA: 0s - loss: 0.0014\n",
      "Epoch 12: val_loss did not improve from 0.00030\n",
      "1939/1939 [==============================] - 30s 16ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 13/100\n",
      "1939/1939 [==============================] - ETA: 0s - loss: 5.8218e-04\n",
      "Epoch 13: val_loss improved from 0.00030 to 0.00006, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 31s 16ms/step - loss: 5.8218e-04 - val_loss: 6.4034e-05\n",
      "Epoch 14/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 3.9225e-04\n",
      "Epoch 14: val_loss improved from 0.00006 to 0.00003, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 30s 15ms/step - loss: 3.9221e-04 - val_loss: 3.0163e-05\n",
      "Epoch 15/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 5.7940e-04\n",
      "Epoch 15: val_loss did not improve from 0.00003\n",
      "1939/1939 [==============================] - 34s 18ms/step - loss: 5.7934e-04 - val_loss: 1.2709e-04\n",
      "Epoch 16/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 3.9292e-04\n",
      "Epoch 16: val_loss did not improve from 0.00003\n",
      "1939/1939 [==============================] - 46s 24ms/step - loss: 3.9292e-04 - val_loss: 4.7969e-05\n",
      "Epoch 17/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 3.1755e-04\n",
      "Epoch 17: val_loss did not improve from 0.00003\n",
      "1939/1939 [==============================] - 44s 23ms/step - loss: 3.1754e-04 - val_loss: 2.5577e-04\n",
      "Epoch 18/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 4.4165e-04\n",
      "Epoch 18: val_loss did not improve from 0.00003\n",
      "1939/1939 [==============================] - 46s 24ms/step - loss: 4.4161e-04 - val_loss: 5.7558e-04\n",
      "Epoch 19/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 3.3053e-04\n",
      "Epoch 19: val_loss did not improve from 0.00003\n",
      "1939/1939 [==============================] - 45s 23ms/step - loss: 3.3060e-04 - val_loss: 4.2339e-04\n",
      "Epoch 20/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 6.4632e-04\n",
      "Epoch 20: val_loss did not improve from 0.00003\n",
      "1939/1939 [==============================] - 46s 24ms/step - loss: 6.4627e-04 - val_loss: 4.5969e-05\n",
      "Epoch 21/100\n",
      "1937/1939 [============================>.] - ETA: 0s - loss: 2.9518e-04\n",
      "Epoch 21: val_loss did not improve from 0.00003\n",
      "1939/1939 [==============================] - 42s 22ms/step - loss: 2.9522e-04 - val_loss: 9.8160e-05\n",
      "Epoch 22/100\n",
      "1939/1939 [==============================] - ETA: 0s - loss: 5.0518e-04\n",
      "Epoch 22: val_loss did not improve from 0.00003\n",
      "1939/1939 [==============================] - 44s 22ms/step - loss: 5.0518e-04 - val_loss: 0.0018\n",
      "Epoch 23/100\n",
      "1937/1939 [============================>.] - ETA: 0s - loss: 2.6194e-04\n",
      "Epoch 23: val_loss did not improve from 0.00003\n",
      "1939/1939 [==============================] - 45s 23ms/step - loss: 2.6182e-04 - val_loss: 1.1228e-04\n",
      "Epoch 24/100\n",
      "1939/1939 [==============================] - ETA: 0s - loss: 2.2527e-04\n",
      "Epoch 24: val_loss did not improve from 0.00003\n",
      "1939/1939 [==============================] - 44s 23ms/step - loss: 2.2527e-04 - val_loss: 1.7441e-04\n",
      "Epoch 25/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 1.8707e-04\n",
      "Epoch 25: val_loss improved from 0.00003 to 0.00003, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 42s 22ms/step - loss: 1.8705e-04 - val_loss: 2.7229e-05\n",
      "Epoch 26/100\n",
      "1939/1939 [==============================] - ETA: 0s - loss: 3.5001e-04\n",
      "Epoch 26: val_loss did not improve from 0.00003\n",
      "1939/1939 [==============================] - 44s 23ms/step - loss: 3.5001e-04 - val_loss: 4.7021e-04\n",
      "Epoch 27/100\n",
      "1939/1939 [==============================] - ETA: 0s - loss: 1.7600e-04\n",
      "Epoch 27: val_loss improved from 0.00003 to 0.00002, saving model to saved_models\\audio_classification_lstm_all.hdf5\n",
      "1939/1939 [==============================] - 43s 22ms/step - loss: 1.7600e-04 - val_loss: 1.9811e-05\n",
      "Epoch 28/100\n",
      "1939/1939 [==============================] - ETA: 0s - loss: 1.8285e-04\n",
      "Epoch 28: val_loss did not improve from 0.00002\n",
      "1939/1939 [==============================] - 44s 23ms/step - loss: 1.8285e-04 - val_loss: 6.4428e-05\n",
      "Epoch 29/100\n",
      "1939/1939 [==============================] - ETA: 0s - loss: 2.8798e-04\n",
      "Epoch 29: val_loss did not improve from 0.00002\n",
      "1939/1939 [==============================] - 33s 17ms/step - loss: 2.8798e-04 - val_loss: 1.8818e-04\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1937/1939 [============================>.] - ETA: 0s - loss: 3.0897e-04\n",
      "Epoch 30: val_loss did not improve from 0.00002\n",
      "1939/1939 [==============================] - 33s 17ms/step - loss: 3.0902e-04 - val_loss: 0.0019\n",
      "Epoch 31/100\n",
      "1937/1939 [============================>.] - ETA: 0s - loss: 1.5068e-04\n",
      "Epoch 31: val_loss did not improve from 0.00002\n",
      "1939/1939 [==============================] - 43s 22ms/step - loss: 1.5060e-04 - val_loss: 1.1246e-04\n",
      "Epoch 32/100\n",
      "1937/1939 [============================>.] - ETA: 0s - loss: 2.1095e-04\n",
      "Epoch 32: val_loss did not improve from 0.00002\n",
      "1939/1939 [==============================] - 40s 20ms/step - loss: 2.1086e-04 - val_loss: 6.9808e-05\n",
      "Epoch 33/100\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 1.9594e-04\n",
      "Epoch 33: val_loss did not improve from 0.00002\n",
      "1939/1939 [==============================] - 28s 14ms/step - loss: 1.9594e-04 - val_loss: 9.8222e-05\n",
      "Epoch 34/100\n",
      "1939/1939 [==============================] - ETA: 0s - loss: 2.0717e-04\n",
      "Epoch 34: val_loss did not improve from 0.00002\n",
      "1939/1939 [==============================] - 28s 15ms/step - loss: 2.0717e-04 - val_loss: 6.0431e-05\n",
      "Epoch 35/100\n",
      " 478/1939 [======>.......................] - ETA: 21s - loss: 1.0647e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_models/audio_classification_lstm_all.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# fit model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrainl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrainl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxtestl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytestl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\engine\\training.py:1555\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   1552\u001b[0m     data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1553\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_load_initial_step_from_ckpt()\n\u001b[0;32m   1554\u001b[0m     )\n\u001b[1;32m-> 1555\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1556\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m         ):\n\u001b[0;32m   1563\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\keras\\engine\\data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1374\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1375\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1376\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1379\u001b[0m )\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\.conda\\envs\\new1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(40, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(100, activation='relu',return_sequences=True))\n",
    "model.add(Dropout(.2))\n",
    "model.add(LSTM(50, activation='relu',return_sequences=True))\n",
    "model.add(Dropout(.2))\n",
    "model.add(LSTM(20, activation='relu'))\n",
    "model.add(Dense(7))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification_lstm_all.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "# fit model\n",
    "model.fit(xtrainl, ytrainl, batch_size=num_batch_size, epochs=num_epochs, validation_data=(xtestl, ytestl), callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9102facf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(xtestl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4b91eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[np.argmax(pred[i]) for i in range(len(pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cee6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytestl=[ytestl[i][0][0] for i in range(len(ytestl))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8a296e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0263219d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytestl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "730680ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17980136721269185"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytestl,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4f3e81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "filename=r\"C:\\mine\\guitar_notes_classification\\sa_sample.wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "# mfccs_scaled_features=(msc.fit_transform(mfccs_scaled_features)).reshape(-1,1)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,1,40)\n",
    "\n",
    "predicted_label=model.predict(mfccs_scaled_features)\n",
    "\n",
    "print(np.argmax(predicted_label))\n",
    "# prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "# prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b103814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef964c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
